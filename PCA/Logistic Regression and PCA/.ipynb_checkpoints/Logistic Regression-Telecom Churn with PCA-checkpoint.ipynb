{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Telecom Churn: Logistic Regression with PCA\n",
    "\n",
    "With 21 predictor variables, we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, customer attrition is referred to as 'churn'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas and NumPy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all datasets\n",
    "churn_data = pd.read_csv(\"churn_data.csv\")\n",
    "customer_data = pd.read_csv(\"customer_data.csv\")\n",
    "internet_data = pd.read_csv(\"internet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043\n",
      "7043\n",
      "7043\n"
     ]
    }
   ],
   "source": [
    "print(len(churn_data))\n",
    "print(len(customer_data))\n",
    "print(len(internet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging on 'customerID'\n",
    "df_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final dataframe with all predictor variables\n",
    "telecom = pd.merge(df_1, internet_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's understand the structure of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  tenure PhoneService        Contract PaperlessBilling  \\\n",
       "0  7590-VHVEG       1           No  Month-to-month              Yes   \n",
       "1  5575-GNVDE      34          Yes        One year               No   \n",
       "2  3668-QPYBK       2          Yes  Month-to-month              Yes   \n",
       "3  7795-CFOCW      45           No        One year               No   \n",
       "4  9237-HQITU       2          Yes  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges TotalCharges Churn  gender  ...  \\\n",
       "0           Electronic check           29.85        29.85    No  Female  ...   \n",
       "1               Mailed check           56.95       1889.5    No    Male  ...   \n",
       "2               Mailed check           53.85       108.15   Yes    Male  ...   \n",
       "3  Bank transfer (automatic)           42.30      1840.75    No    Male  ...   \n",
       "4           Electronic check           70.70       151.65   Yes  Female  ...   \n",
       "\n",
       "   Partner Dependents     MultipleLines InternetService OnlineSecurity  \\\n",
       "0      Yes         No  No phone service             DSL             No   \n",
       "1       No         No                No             DSL            Yes   \n",
       "2       No         No                No             DSL            Yes   \n",
       "3       No         No  No phone service             DSL            Yes   \n",
       "4       No         No                No     Fiber optic             No   \n",
       "\n",
       "  OnlineBackup DeviceProtection TechSupport StreamingTV StreamingMovies  \n",
       "0          Yes               No          No          No              No  \n",
       "1           No              Yes          No          No              No  \n",
       "2          Yes               No          No          No              No  \n",
       "3           No              Yes         Yes          No              No  \n",
       "4           No               No          No          No              No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the head of our master dataset\n",
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.371149</td>\n",
       "      <td>64.761692</td>\n",
       "      <td>0.162147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.559481</td>\n",
       "      <td>30.090047</td>\n",
       "      <td>0.368612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  MonthlyCharges  SeniorCitizen\n",
       "count  7043.000000     7043.000000    7043.000000\n",
       "mean     32.371149       64.761692       0.162147\n",
       "std      24.559481       30.090047       0.368612\n",
       "min       0.000000       18.250000       0.000000\n",
       "25%       9.000000       35.500000       0.000000\n",
       "50%      29.000000       70.350000       0.000000\n",
       "75%      55.000000       89.850000       0.000000\n",
       "max      72.000000      118.750000       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Yes to 1 and No to 0\n",
    "telecom['PhoneService'] = telecom['PhoneService'].map({'Yes': 1, 'No': 0})\n",
    "telecom['PaperlessBilling'] = telecom['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Churn'] = telecom['Churn'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Partner'] = telecom['Partner'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Dependents'] = telecom['Dependents'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy variable for the variable 'Contract' and dropping the first one.\n",
    "cont = pd.get_dummies(telecom['Contract'],prefix='Contract',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,cont],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'PaymentMethod' and dropping the first one.\n",
    "pm = pd.get_dummies(telecom['PaymentMethod'],prefix='PaymentMethod',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,pm],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'gender' and dropping the first one.\n",
    "gen = pd.get_dummies(telecom['gender'],prefix='gender',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,gen],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'MultipleLines' and dropping the first one.\n",
    "ml = pd.get_dummies(telecom['MultipleLines'],prefix='MultipleLines')\n",
    "#  dropping MultipleLines_No phone service column\n",
    "ml1 = ml.drop(['MultipleLines_No phone service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ml1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'InternetService' and dropping the first one.\n",
    "iser = pd.get_dummies(telecom['InternetService'],prefix='InternetService',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,iser],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'OnlineSecurity'.\n",
    "os = pd.get_dummies(telecom['OnlineSecurity'],prefix='OnlineSecurity')\n",
    "os1= os.drop(['OnlineSecurity_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,os1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'OnlineBackup'.\n",
    "ob =pd.get_dummies(telecom['OnlineBackup'],prefix='OnlineBackup')\n",
    "ob1 =ob.drop(['OnlineBackup_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ob1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'DeviceProtection'. \n",
    "dp =pd.get_dummies(telecom['DeviceProtection'],prefix='DeviceProtection')\n",
    "dp1 = dp.drop(['DeviceProtection_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,dp1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'TechSupport'. \n",
    "ts =pd.get_dummies(telecom['TechSupport'],prefix='TechSupport')\n",
    "ts1 = ts.drop(['TechSupport_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ts1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'StreamingTV'.\n",
    "st =pd.get_dummies(telecom['StreamingTV'],prefix='StreamingTV')\n",
    "st1 = st.drop(['StreamingTV_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,st1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'StreamingMovies'. \n",
    "sm =pd.get_dummies(telecom['StreamingMovies'],prefix='StreamingMovies')\n",
    "sm1 = sm.drop(['StreamingMovies_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,sm1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the repeated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created dummies for the below variables, so we can drop them\n",
    "telecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'convert_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4feb493fd60b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#The varaible was imported as a string we need to convert it to float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtelecom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TotalCharges'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtelecom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TotalCharges'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#telecom['tenure'] = telecom['tenure'].astype(int).astype(float)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installations\\Annaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'convert_objects'"
     ]
    }
   ],
   "source": [
    "#The varaible was imported as a string we need to convert it to float\n",
    "telecom['TotalCharges'] =telecom['TotalCharges'].convert_objects(convert_numeric=True)\n",
    "#telecom['tenure'] = telecom['tenure'].astype(int).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see we have all variables as integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "num_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers at 25%,50%,75%,90%,95% and 99%\n",
    "num_telecom.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution shown above, you can see that there no outliner in your data. The numbers are gradually increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing Values and Inputing Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that 11/7043 = 0.001561834 i.e 0.1%, best is to remove these observations from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of missing values\n",
    "round(100*(telecom.isnull().sum()/len(telecom.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN TotalCharges rows\n",
    "telecom = telecom[~np.isnan(telecom['TotalCharges'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking percentage of missing values after removing the missing values\n",
    "round(100*(telecom.isnull().sum()/len(telecom.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't have any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising continuous features\n",
    "df = telecom[['tenure','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(df-df.mean())/df.std()\n",
    "telecom = telecom.drop(['tenure','MonthlyCharges','TotalCharges'], 1)\n",
    "telecom = pd.concat([telecom,normalized_df],axis=1)\n",
    "telecom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = (sum(telecom['Churn'])/len(telecom['Churn'].index))*100\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have almost 27% churn rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Let's start by splitting our data into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting feature variable to X\n",
    "X = telecom.drop(['Churn','customerID'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = telecom['Churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Your First Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(telecom.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping highly correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)\n",
    "X_train2 = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping highly correlated variables now let's check the correlation matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(X_train2.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our model again after dropping highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm2 = sm.GLM(y_train,(sm.add_constant(X_train2)), family = sm.families.Binomial())\n",
    "logm2.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 13)             # running RFE with 13 variables as output\n",
    "rfe = rfe.fit(X,y)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)           # Printing the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables selected by RFE \n",
    "col = ['PhoneService', 'PaperlessBilling', 'Contract_One year', 'Contract_Two year',\n",
    "       'PaymentMethod_Electronic check','MultipleLines_No','InternetService_Fiber optic', 'InternetService_No',\n",
    "       'OnlineSecurity_Yes','TechSupport_Yes','StreamingMovies_No','tenure','TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the model using the selected variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logsk = LogisticRegression(C=1e9)\n",
    "#logsk.fit(X_train[col], y_train)\n",
    "logsk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the model with StatsModels\n",
    "#logm4 = sm.GLM(y_train,(sm.add_constant(X_train[col])), family = sm.families.Binomial())\n",
    "logm4 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "modres = logm4.fit()\n",
    "logm4.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[col].shape\n",
    "#res = modres.predict(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities\n",
    "y_pred = logsk.predict_proba(X_test)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "# Converting to column dataframe\n",
    "y_pred_1 = y_pred_df.iloc[:,[1]]\n",
    "# Let's see the head\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['CustID'] = y_test_df.index\n",
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df,y_pred_1],axis=1)\n",
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 1 : 'Churn_Prob'})\n",
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex_axis(['CustID','Churn','Churn_Prob'], axis=1)\n",
    "# Let's see the head of y_pred_final\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\n",
    "y_pred_final['predicted'] = y_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.5 else 0)\n",
    "# Let's see the head\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix( y_pred_final.Churn, y_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted     Churn  not_churn  __all__\n",
    "# Actual\n",
    "# Churn            1359   169     1528\n",
    "# not_churn         256   326      582\n",
    "# __all__          1615   751     2110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Churn, y_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_pred_final.Churn, y_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_roc(y_pred_final.Churn, y_pred_final.predicted)\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_pred_final.Churn, y_pred_final.Churn_Prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see an overall AUC score of 0.83 looks like we did a decent job.\n",
    "- But we did spend a lot of effort on the features and their selection.\n",
    "- Can PCA help reduce our effort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - \n",
    "- While computng the principal components, we must not include the entire dataset. Model building is all about doing well on the data we haven't seen yet!\n",
    "- So we'll calculate the PCs using the train data, and apply them later on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components from the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the explained variance ratio for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a scree plot for the explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=0.95, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA with 16 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = IncrementalPCA(n_components=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = np.corrcoef(df_train_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the heatmap of the corr matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corrmat, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the transformation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying logistic regression on the data on our Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = learner_pca.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test = model_pca.predict_proba(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making it a little more unsupervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_again = PCA(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca2 = pca_again.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following it up with a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca2 = learner_pca2.fit(df_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca2 = pca_again.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
